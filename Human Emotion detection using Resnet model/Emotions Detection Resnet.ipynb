{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU","gpuClass":"standard"},"cells":[{"cell_type":"code","metadata":{"id":"kymKPWIS9QHA","executionInfo":{"status":"ok","timestamp":1670063120547,"user_tz":-300,"elapsed":3161,"user":{"displayName":"Zainab Bibi","userId":"04957673229875639387"}}},"source":["from keras.layers import Input, Lambda, Dense, Flatten\n","from keras.models import Model\n","from keras.applications.vgg16 import VGG16\n","from keras.applications.vgg16 import preprocess_input\n","from keras.preprocessing import image\n","from keras.preprocessing.image import ImageDataGenerator\n","from keras.models import Sequential\n","import numpy as np\n","from glob import glob\n","import matplotlib.pyplot as plt\n","\n","import warnings\n","warnings.filterwarnings(\"ignore\", category=FutureWarning)"],"execution_count":1,"outputs":[]},{"cell_type":"code","metadata":{"id":"ztvnQbfNL13G","executionInfo":{"status":"ok","timestamp":1670063120550,"user_tz":-300,"elapsed":13,"user":{"displayName":"Zainab Bibi","userId":"04957673229875639387"}}},"source":["IMAGE_SIZE = [224, 224]"],"execution_count":2,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"UyDyxaIHk0vC","outputId":"6917acab-9d38-40b7-e29e-80b46d00bfd7","executionInfo":{"status":"ok","timestamp":1670063146057,"user_tz":-300,"elapsed":25519,"user":{"displayName":"Zainab Bibi","userId":"04957673229875639387"}}},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","metadata":{"id":"79xfCi1VL4WE","executionInfo":{"status":"ok","timestamp":1670063146060,"user_tz":-300,"elapsed":26,"user":{"displayName":"Zainab Bibi","userId":"04957673229875639387"}}},"source":["#Give dataset path\n","train_path = '/content/drive/My Drive/Colab Notebooks/em_de/emotion_detection/train'\n","validate_path='/content/drive/My Drive/Colab Notebooks/em_de/emotion_detection/test'"],"execution_count":4,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"nXzCeUIa4APa","outputId":"4885b81d-e64c-43ea-dddd-65d92eb299c2","executionInfo":{"status":"ok","timestamp":1670063177591,"user_tz":-300,"elapsed":31553,"user":{"displayName":"Zainab Bibi","userId":"04957673229875639387"}}},"source":["from PIL import Image \n","import os \n","from IPython.display import display\n","from IPython.display import Image as _Imgdis\n","# creating a object \n","folder = train_path+'/angry'\n","onlybenignfiles = [f for f in os.listdir(folder) if os.path.isfile(os.path.join(folder, f))]\n","print(\"Working with {0} images\".format(len(onlybenignfiles)))\n","print(\"Image examples: \")\n","for i in range(5):\n","    print(onlybenignfiles[i])\n","    display(_Imgdis(filename=folder + \"/\" + onlybenignfiles[i], width=240, height=240))"],"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["Working with 4005 images\n","Image examples: \n","im3102.png\n"]},{"output_type":"display_data","data":{"image/png":"iVBORw0KGgoAAAANSUhEUgAAADAAAAAwCAAAAAByaaZbAAAGdklEQVR4nCXSTY8cVxWA4fN161ZVV3fX9Hx4xp4JeAy2gkQIgghBAmKVDRIbWCLxw9iwyg4h4A+gSEgQhUWCFYISbDN24ok9npnu6a6uunXPOSzyE95HLz7Yeiq9L5h2H8yrZtaW0RHRA6ErGBEzjpYdvvjjWbGxPVICQCVGKdmgqAt2cnNBREZzLGIgNyS5/Z1hqH1DLgigkQMEACrKomBmYURhJy6rdl7GQlCkfvP2cggDqTibF4DOY8a6KlhECAGILXEZfTh/1iUsYnHnJ7IxEMqOJsQWApkUIsAZiNCSGSdP1+ebnKtmejwrf/zRhxjEncwZ47pko7oQJGcjcEME6D/7z5e97xzGDV3K/PYvPlu7gCNlgNECKdXkRECZfVQQv/j0w8ss9x+c7E6JMBc/+vmfsyiKA4C62MjB1RBM3DPk/vyjh2bzuVyM6E30LPUvH54JKnMG6kEUK4Gs6CBu1qeLTx97UY9nj7Q+vX96q2Ifv/Xue0LJ4kA2BDYXtDyCaUAbb1ZffmXT3F1hD+njp5ffvzVztXc+EAMWNANxo8KVB7WRo5u9urSpXUs8P6p67R41VW3aH7wjDqAKBqQwnRF0N84FV2TjkGq+ltNv/u5y9atbn92fFoKg/ANRBAVQZUG5eNKNBPVOvVdk2sPVGO2399o/tb/+9PAtB2G3vCOGOAK6wxWvP0lcSKy7RZyJlLPz6y4a/+aH68vqyCWwq2oWMAM0to3hkpoCVXUTB6groz26mD3tX34Fzd6cWAAAUhZUp+xuAx/u6aveEefiWSYVDcLaLv+rxTRERgIwc02ChmCmuDierK6XMA4tHImmIDtpW8erlapjyU7oNo7mJmoKoFYdxBdPsExrXk54XzoQmkPZnl1WSpMAqkh5zDY6EYy9GgAsvxjfeKMourvTl23URGMseXrveBLBcra03Q4pJWAxGhUMMK27o7s/e+t9/8aNbBsf8hjrbJN7h6sEHHk0wDwKojiCoqNtl1QP67dPzm5ij1FHdSwQs9eSDGxUc1JwR+EMDoi6ATqPO8/KbKFuS7UU+sLBTA1cPWcHc1RkIQcHB4w8VgfT2ryuw5THvClyAgdVcFczQFc0IJaMagwOEuoYE1MZyiqOqNsoBWvSpZZSOIFlQEBAcQBEd6RAk3pSIxQNjeqmSW0+v1nJ5XrHAoIhmAdCcXAAAMJQv/Zgj7wQukmORiJ9KPpxNp7prEEzI0IEFNKvGwwWp0cVuLjaWlwn1KXlv/pmEsqtYyQBAAICQXR0AEKqOI9M2XXsTOL2as1dFx8NpwdV3lJgAARCFDcjB0AQyQkDI7ilbtZsr4btdfP0n69vy0nSEBTZCICEDMABCCQPHYkhAmrOunzVG/bVu/u3KimNoho5OaCYkzk6sOmYyc3JjLi/fPx0e1+6b99DygErs2AO6Abihv41bc45Abi4SUkp3Ll1OFIJJSVhQ83y9apioAaA7j4OOjgQggkWdaBYndRrrnlWWrdNUEYCMxAwAwB3M+3WOHIhFiqXrBbnu0jdkxd9bI+qjQMSIriYATp43xV9d2XTgrLE4EoWduV/m/zF47Rc4eye8ff2KhJwMTJH98BXTgicgQOT5XKnfvHwq6X4agvtBJ5N775iZAsuigBu+6/D+fPLnfbVwYI5sFM5+8f7yc21ODndO866gPNhVTkiziwXUJ/u4WbD++3Vdr89WICE5oO/Jpd5e/ew5Rec6lkZNqNIORFHmfOt3YUsoLrdpMXOi78/P6X08d90fnx4NAn28svrerd0VcPkUcVoEhb7JztVsGkbpgf1vfkfLk7OVrP58Zw2z7pujZMiWA8ZRdAzxkmzOzs9rkvgttlpCobtv99bvfkara42G82GxtViPovCJSOIYl0fTva+20Sm6X4zicJo3cPfw09xoymPm8Gr/VZiyRIKNrEbQZnibkSAetHUQshkxcnbf/no9QJkoLI+3FtA3zkKkYF2JlTLZJeZ64O2CixMNuK0PXlUnYQihvJOO46hFnUAVOi2M8FJ1TYYyt15KSLCQJAc28vP+aAqmik873xaILOBQbqc1BLaZq5Yz+eRRAgcQVfnz+X4k+dFCHnYXHN5RV5KIKeXwyHK9I5FnM3aWoSRwFC3w8XzarGzvCpDstU4ScMWJk0BYf3quES5W3XSzGd1CMxgDLlfD49WLe9/ftPMIY0um07VlcBXi/kI/we4cb2gOyw+8AAAAABJRU5ErkJggg==\n","text/plain":["<IPython.core.display.Image object>"]},"metadata":{"image/png":{"width":240,"height":240}}},{"output_type":"stream","name":"stdout","text":["im669.png\n"]},{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<IPython.core.display.Image object>"]},"metadata":{"image/png":{"width":240,"height":240}}},{"output_type":"stream","name":"stdout","text":["im3711.png\n"]},{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<IPython.core.display.Image object>"]},"metadata":{"image/png":{"width":240,"height":240}}},{"output_type":"stream","name":"stdout","text":["im3543.png\n"]},{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<IPython.core.display.Image object>"]},"metadata":{"image/png":{"width":240,"height":240}}},{"output_type":"stream","name":"stdout","text":["im3204.png\n"]},{"output_type":"display_data","data":{"image/png":"iVBORw0KGgoAAAANSUhEUgAAADAAAAAwCAAAAAByaaZbAAAGHUlEQVR4nDWTS3NcVxWF197ndZ/derRkKXacJ3EqKQKECWOGjJnDT+QfMGMCE4pUoFwpyhgnthxZUkutvt33nLMXA4U93/WtVXt/4l3swz6f7sYn2Lx7g0mHVXlT6VI5TWvnXAo3R7X7Ylm9cwL4gtTsQr/tDqYuLK+nwHb5emv9V+zO1/86kiO9fp2CC5UGKsVLOopzDqXBbnF0+fTdxfFnZ/cpfvmbJsS34Rz9ndRuf/msgs4E4peL49yX+5CnxvqtPdPms/ZZPPtibII+PnV2v4xlfTVNB4UCQv1w2NW6r2OWNuBsd/g4nPMXn7UtVBi9Zav1jvr+YGABUP3Q9tuQu9aHoY/axEXUEJdi1aAiDk3e61JnKUYKIF6AnS6pcTEmH33T+cZRo+VKF52W6Opq9P+pxX6KpKH6UbnDoQuxSV3XKNRam42hcZgdpo/HV28EJKGgb8CDZtbOYts2bWq64L0GWNpJbHw2Mo5deRvsgQAvWI4KjsV1SSOYEbwmN2V1yAFzqYcplpbBIATp2/fGIQXnQnJJKaDO+056t88NYazS9y3jk6yeJgrzg4YmdU3btCmxiqu1XN9VWLX7yKqpZcT3N+qgnhSIj3IdF+2yH1pOTM5XMl7l7bwNyNw1o9u+3ty+vPq4hxoA+m7VTHHouH5zu/NEYtPUepNFqLab7Li8eXvJ4Ukf1Qgh/ceMg7MXF5i7Zt7f3Ga2q34jQ6jj/cV6/7fbent3dnomCCYUoe+qcf39ml1nF9dXbzd5GC5aLvJKWd6+/HG+Ofr8+T/seAQdIIB3yHOpS9s9f7GNr+PR1dTVTR9PVo1y/ffpZP31H//y5w/WbVchgNA7+BJ4++6bN3fd+9Onf/j2TzcHy6PT00UqejNy8/Pfz9Pnv/3mxS8zIAB8DVZ3ZXt59Sx887L93fnrr+/O09nx4XHaXrz/ngtnPzxffLQ4+PbLVEUI80i+q9vl8bN5fLr5aPXXi/MPXVodjctxuvpwc9PMpTs4Sv3Ce4UJxMfoVSG8XZfTML2q7bw4SItuCBIPHy3GuYlpSKX9VWtKB9AH+KTe2bC8nmbH7J+cuZCCA5qD883JBqlL3hoHgQCgNwBOg0OznHfbzLQK4rxDMXVxkG4t6sOuCn4aLyU7J1TnNDQhy0GbFZRsLvWxSpP2otyaMxAU0Fet2RvEeZ9r7NpQq7dq2nZRljOk63LdTiJCAgR8EYKukMlpk4ITr9Uqm8Xg3PFmCoEElWYESMDTkFEKYDFEp4Ji+zIxCVS7bh2DZ1FXaaDBCE9aVSdWrXonhJX9/X3x+90odIPdSeKDzyRJg1aCRoERKBU17zebTW1s2hYUN1AMgAICgYiKBxxRnHgrjmq55vkuPho376RIvU/7DOYiSsoDxasDiquaxRicE+zm+27w08168Hq9OauxZAlKEkYjvYgYXXaWDSCliN45fvft0SeD1n9++pTZ6OkeathPl4b56g1VAJYwHD7Pt2n73bncfvKVWDFLMIIgafRSIqlEFVRYjc63nywuq8i6PHr6OFWwWgAAkjAzT1Y+4ERgtOjd2D++28thPo5OHOqs0QQgQFbzVSkwVghBoaMB0EasTdHNZJ7KoTcIBKSpeav0AgPpoKKoM6vU6kMfk22nXc3SOhUBAJqZrwwm3qykRKE0+70BCGZjf/udO85bHLWU/y/QPMwoEPNiwup2UyEa9/2PczNc/bg/H7pxqRQRCEE18SZVQYVYVeYy37/b+/vLGwQuNOd/jx89WlJERCgQKr0BIgVCYQXy/auX25ODxz9zTt87ubvaQs+UD3ZCCMJPyUQJcaxg3m30110+GFbBZplL7fPZMDsKBBQKAf9q1ZFKZxBBzl0Xvd9ub32i1D1yfzqLqYgoRCtZ/f6/q6U5eqgoLahD9WG+D+vZScb4qFBVRaGqRlr13fzD5rAHFc4IZ4V5J/Nuu9O+C8sTtxd1Igp1IlLNfPHN5Xp12AbvnTjRmqWban8U6Zz0fRaBqYjaw+tUv7oMi/WLq9WyCTF4Ua8SFzHWqk3ZjlJFTAioqAho5uvxBXpeXh+fLCrh1Aml8dXMpeKTCQGawKAC0Pg/UBS84DhbHMgAAAAASUVORK5CYII=\n","text/plain":["<IPython.core.display.Image object>"]},"metadata":{"image/png":{"width":240,"height":240}}}]},{"cell_type":"code","metadata":{"id":"HDHko5V6MaVr","executionInfo":{"status":"ok","timestamp":1670063183702,"user_tz":-300,"elapsed":6127,"user":{"displayName":"Zainab Bibi","userId":"04957673229875639387"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"b53c20b3-2bc8-4dbd-c99c-7bd541a76c69"},"source":["vgg = VGG16(input_shape=IMAGE_SIZE + [3], weights='imagenet', include_top=False)"],"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n","58889256/58889256 [==============================] - 2s 0us/step\n"]}]},{"cell_type":"code","metadata":{"id":"Lt7P2RKid8PU","colab":{"base_uri":"https://localhost:8080/"},"outputId":"ca9d2b5e-e7c4-41fa-86c0-b48f32d89c02","executionInfo":{"status":"ok","timestamp":1670063183703,"user_tz":-300,"elapsed":62,"user":{"displayName":"Zainab Bibi","userId":"04957673229875639387"}}},"source":["vgg.input"],"execution_count":7,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<KerasTensor: shape=(None, 224, 224, 3) dtype=float32 (created by layer 'input_1')>"]},"metadata":{},"execution_count":7}]},{"cell_type":"code","metadata":{"id":"cwdsXOLlMdiR","executionInfo":{"status":"ok","timestamp":1670063183705,"user_tz":-300,"elapsed":33,"user":{"displayName":"Zainab Bibi","userId":"04957673229875639387"}}},"source":["for layer in vgg.layers:\n","  layer.trainable = False"],"execution_count":8,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"jR_L6S1_lr4L","outputId":"e6fe6433-e8f3-4f1f-c9e2-4e6e820a8795","executionInfo":{"status":"ok","timestamp":1670063183706,"user_tz":-300,"elapsed":31,"user":{"displayName":"Zainab Bibi","userId":"04957673229875639387"}}},"source":["folders = glob('/content/drive/My Drive/Colab Notebooks/em_de/emotion_detection/train/*')\n","print(len(folders))"],"execution_count":9,"outputs":[{"output_type":"stream","name":"stdout","text":["7\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"G56cRtmvMiVj","outputId":"041ec74f-3f46-41e1-837b-7718d13dd881","executionInfo":{"status":"ok","timestamp":1670063184483,"user_tz":-300,"elapsed":796,"user":{"displayName":"Zainab Bibi","userId":"04957673229875639387"}}},"source":["from tensorflow.keras import layers, models\n","x = Flatten()(vgg.output)\n","prediction =Dense(len(folders), activation='softmax')(x)\n","model = Model(inputs=vgg.input, outputs=prediction)\n","model.summary()"],"execution_count":10,"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"model\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," input_1 (InputLayer)        [(None, 224, 224, 3)]     0         \n","                                                                 \n"," block1_conv1 (Conv2D)       (None, 224, 224, 64)      1792      \n","                                                                 \n"," block1_conv2 (Conv2D)       (None, 224, 224, 64)      36928     \n","                                                                 \n"," block1_pool (MaxPooling2D)  (None, 112, 112, 64)      0         \n","                                                                 \n"," block2_conv1 (Conv2D)       (None, 112, 112, 128)     73856     \n","                                                                 \n"," block2_conv2 (Conv2D)       (None, 112, 112, 128)     147584    \n","                                                                 \n"," block2_pool (MaxPooling2D)  (None, 56, 56, 128)       0         \n","                                                                 \n"," block3_conv1 (Conv2D)       (None, 56, 56, 256)       295168    \n","                                                                 \n"," block3_conv2 (Conv2D)       (None, 56, 56, 256)       590080    \n","                                                                 \n"," block3_conv3 (Conv2D)       (None, 56, 56, 256)       590080    \n","                                                                 \n"," block3_pool (MaxPooling2D)  (None, 28, 28, 256)       0         \n","                                                                 \n"," block4_conv1 (Conv2D)       (None, 28, 28, 512)       1180160   \n","                                                                 \n"," block4_conv2 (Conv2D)       (None, 28, 28, 512)       2359808   \n","                                                                 \n"," block4_conv3 (Conv2D)       (None, 28, 28, 512)       2359808   \n","                                                                 \n"," block4_pool (MaxPooling2D)  (None, 14, 14, 512)       0         \n","                                                                 \n"," block5_conv1 (Conv2D)       (None, 14, 14, 512)       2359808   \n","                                                                 \n"," block5_conv2 (Conv2D)       (None, 14, 14, 512)       2359808   \n","                                                                 \n"," block5_conv3 (Conv2D)       (None, 14, 14, 512)       2359808   \n","                                                                 \n"," block5_pool (MaxPooling2D)  (None, 7, 7, 512)         0         \n","                                                                 \n"," flatten (Flatten)           (None, 25088)             0         \n","                                                                 \n"," dense (Dense)               (None, 7)                 175623    \n","                                                                 \n","=================================================================\n","Total params: 14,890,311\n","Trainable params: 175,623\n","Non-trainable params: 14,714,688\n","_________________________________________________________________\n"]}]},{"cell_type":"code","metadata":{"id":"L6x9IHTBM1CA","executionInfo":{"status":"ok","timestamp":1670063184488,"user_tz":-300,"elapsed":30,"user":{"displayName":"Zainab Bibi","userId":"04957673229875639387"}}},"source":["from keras import optimizers\n","adam = optimizers.Adam()\n","model.compile(loss='categorical_crossentropy',\n","              optimizer=adam,\n","              metrics=['accuracy'])"],"execution_count":11,"outputs":[]},{"cell_type":"code","metadata":{"id":"l0YRD6xfnnrk","executionInfo":{"status":"ok","timestamp":1670063184489,"user_tz":-300,"elapsed":28,"user":{"displayName":"Zainab Bibi","userId":"04957673229875639387"}}},"source":["train_datagen = ImageDataGenerator(rescale = 1./255,\n","                                   shear_range = 0.2,\n","                                   zoom_range = 0.2,\n","                                   horizontal_flip = True)"],"execution_count":12,"outputs":[]},{"cell_type":"code","source":["test_datagen = ImageDataGenerator(rescale = 1./255)"],"metadata":{"id":"BxKdw0WWMXbi","executionInfo":{"status":"ok","timestamp":1670063184491,"user_tz":-300,"elapsed":28,"user":{"displayName":"Zainab Bibi","userId":"04957673229875639387"}}},"execution_count":13,"outputs":[]},{"cell_type":"code","source":["training_set = train_datagen.flow_from_directory('/content/drive/My Drive/Colab Notebooks/em_de/emotion_detection/train',\n","                                                 target_size = (224, 224),\n","                                                 batch_size = 32,\n","                                                 class_mode = 'categorical')"],"metadata":{"id":"rBqp0BpKMXdW","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1670063209394,"user_tz":-300,"elapsed":24928,"user":{"displayName":"Zainab Bibi","userId":"04957673229875639387"}},"outputId":"c8c89191-3ba2-4d64-dd6b-6a2a0ad5e963"},"execution_count":14,"outputs":[{"output_type":"stream","name":"stdout","text":["Found 28799 images belonging to 7 classes.\n"]}]},{"cell_type":"code","source":["test_set = test_datagen.flow_from_directory('/content/drive/My Drive/Colab Notebooks/em_de/emotion_detection/test',\n","                                            target_size = (224, 224),\n","                                            batch_size = 32,\n","                                            class_mode = 'categorical')"],"metadata":{"id":"eQ5NH11aMXfw","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1670063218310,"user_tz":-300,"elapsed":8971,"user":{"displayName":"Zainab Bibi","userId":"04957673229875639387"}},"outputId":"f8f98c40-c189-44c9-e4f2-20572270a18c"},"execution_count":15,"outputs":[{"output_type":"stream","name":"stdout","text":["Found 7194 images belonging to 7 classes.\n"]}]},{"cell_type":"code","source":["from datetime import datetime\n","from keras.callbacks import ModelCheckpoint, EarlyStopping\n","# checkpoint = ModelCheckpoint(filepath='mymodel.h5', verbose=1, save_best_only=True)\n","# callbacks = [checkpoint]\n","start = datetime.now()\n","\n","early = EarlyStopping(monitor='val_acc', min_delta=0, patience=20, verbose=1, mode='auto')\n","checkpoint = ModelCheckpoint(\"vgg16_1.h5\", monitor='val_acc', verbose=1, save_best_only=True, save_weights_only=False, mode='auto', period=1)\n","model_history=model.fit_generator(\n","  training_set,\n","  validation_data=test_set,\n","  epochs=100,\n","  steps_per_epoch=len(training_set)/32,\n","  validation_steps=len(test_set)/32,\n","  callbacks=[checkpoint,early],\n","  verbose=1)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"z5f-2zNH6b6z","outputId":"323df8e9-32a5-4ca5-99e9-d44b1d004c7c"},"execution_count":null,"outputs":[{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n","<ipython-input-24-7e4d0aff40d3>:9: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n","  model_history=model.fit_generator(\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Epoch 1/100\n","29/28 [==============================] - ETA: -9s - loss: 1.6004 - accuracy: 0.3901"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n","WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n"]},{"output_type":"stream","name":"stdout","text":["28/28 [==============================] - 337s 12s/step - loss: 1.6004 - accuracy: 0.3901 - val_loss: 1.6103 - val_accuracy: 0.4277\n","Epoch 2/100\n","29/28 [==============================] - ETA: -9s - loss: 1.6696 - accuracy: 0.3922"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n","WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r28/28 [==============================] - 310s 11s/step - loss: 1.6696 - accuracy: 0.3922 - val_loss: 2.0812 - val_accuracy: 0.3154\n","Epoch 3/100\n","29/28 [==============================] - ETA: -9s - loss: 1.6471 - accuracy: 0.4203"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n","WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r28/28 [==============================] - 321s 11s/step - loss: 1.6471 - accuracy: 0.4203 - val_loss: 1.3934 - val_accuracy: 0.4863\n","Epoch 4/100\n","29/28 [==============================] - ETA: -8s - loss: 1.4892 - accuracy: 0.4688"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n","WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r28/28 [==============================] - 287s 10s/step - loss: 1.4892 - accuracy: 0.4688 - val_loss: 1.4849 - val_accuracy: 0.4746\n","Epoch 5/100\n","29/28 [==============================] - ETA: -8s - loss: 1.4265 - accuracy: 0.4677"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n","WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r28/28 [==============================] - 270s 10s/step - loss: 1.4265 - accuracy: 0.4677 - val_loss: 1.4787 - val_accuracy: 0.4697\n","Epoch 6/100\n","29/28 [==============================] - ETA: -8s - loss: 1.4218 - accuracy: 0.4688"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n","WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r28/28 [==============================] - 282s 10s/step - loss: 1.4218 - accuracy: 0.4688 - val_loss: 1.5133 - val_accuracy: 0.4043\n","Epoch 7/100\n","29/28 [==============================] - ETA: -7s - loss: 1.5919 - accuracy: 0.4159"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n","WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r28/28 [==============================] - 264s 9s/step - loss: 1.5919 - accuracy: 0.4159 - val_loss: 1.6778 - val_accuracy: 0.4033\n","Epoch 8/100\n","29/28 [==============================] - ETA: -8s - loss: 1.5799 - accuracy: 0.4095"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n","WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r28/28 [==============================] - 271s 10s/step - loss: 1.5799 - accuracy: 0.4095 - val_loss: 1.6060 - val_accuracy: 0.4092\n","Epoch 9/100\n","29/28 [==============================] - ETA: -7s - loss: 1.4200 - accuracy: 0.4881"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n","WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r28/28 [==============================] - 254s 9s/step - loss: 1.4200 - accuracy: 0.4881 - val_loss: 1.4157 - val_accuracy: 0.4941\n","Epoch 10/100\n","29/28 [==============================] - ETA: -7s - loss: 1.3906 - accuracy: 0.4795"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n","WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r28/28 [==============================] - 239s 9s/step - loss: 1.3906 - accuracy: 0.4795 - val_loss: 1.4369 - val_accuracy: 0.4775\n","Epoch 11/100\n","29/28 [==============================] - ETA: -6s - loss: 1.4483 - accuracy: 0.4677"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n","WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r28/28 [==============================] - 229s 8s/step - loss: 1.4483 - accuracy: 0.4677 - val_loss: 1.7193 - val_accuracy: 0.4297\n","Epoch 12/100\n","29/28 [==============================] - ETA: -6s - loss: 1.4807 - accuracy: 0.4634"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n","WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r28/28 [==============================] - 220s 8s/step - loss: 1.4807 - accuracy: 0.4634 - val_loss: 1.4980 - val_accuracy: 0.4883\n","Epoch 13/100\n","29/28 [==============================] - ETA: -6s - loss: 1.4045 - accuracy: 0.4849"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n","WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r28/28 [==============================] - 215s 8s/step - loss: 1.4045 - accuracy: 0.4849 - val_loss: 1.5488 - val_accuracy: 0.4570\n","Epoch 14/100\n","29/28 [==============================] - ETA: -6s - loss: 1.4840 - accuracy: 0.4860"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n","WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r28/28 [==============================] - 221s 8s/step - loss: 1.4840 - accuracy: 0.4860 - val_loss: 1.4501 - val_accuracy: 0.4688\n","Epoch 15/100\n","29/28 [==============================] - ETA: -6s - loss: 1.4517 - accuracy: 0.4720"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n","WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r28/28 [==============================] - 210s 7s/step - loss: 1.4517 - accuracy: 0.4720 - val_loss: 1.3624 - val_accuracy: 0.5010\n","Epoch 16/100\n","29/28 [==============================] - ETA: -6s - loss: 1.4052 - accuracy: 0.4881"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n","WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r28/28 [==============================] - 204s 7s/step - loss: 1.4052 - accuracy: 0.4881 - val_loss: 1.4669 - val_accuracy: 0.4531\n","Epoch 17/100\n","29/28 [==============================] - ETA: -5s - loss: 1.4858 - accuracy: 0.4461"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n","WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r28/28 [==============================] - 193s 7s/step - loss: 1.4858 - accuracy: 0.4461 - val_loss: 1.5522 - val_accuracy: 0.4297\n","Epoch 18/100\n","29/28 [==============================] - ETA: -5s - loss: 1.4328 - accuracy: 0.4720"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n","WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r28/28 [==============================] - 195s 7s/step - loss: 1.4328 - accuracy: 0.4720 - val_loss: 1.4195 - val_accuracy: 0.4717\n","Epoch 19/100\n","29/28 [==============================] - ETA: -5s - loss: 1.4320 - accuracy: 0.4795"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n","WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r28/28 [==============================] - 174s 6s/step - loss: 1.4320 - accuracy: 0.4795 - val_loss: 1.3326 - val_accuracy: 0.5244\n","Epoch 20/100\n","29/28 [==============================] - ETA: -5s - loss: 1.3557 - accuracy: 0.5119"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n","WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r28/28 [==============================] - 180s 6s/step - loss: 1.3557 - accuracy: 0.5119 - val_loss: 1.5121 - val_accuracy: 0.4297\n","Epoch 21/100\n","29/28 [==============================] - ETA: -5s - loss: 1.3770 - accuracy: 0.4838"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n","WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r28/28 [==============================] - 181s 6s/step - loss: 1.3770 - accuracy: 0.4838 - val_loss: 1.4065 - val_accuracy: 0.4854\n","Epoch 22/100\n","29/28 [==============================] - ETA: -5s - loss: 1.3795 - accuracy: 0.4849"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n","WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r28/28 [==============================] - 176s 6s/step - loss: 1.3795 - accuracy: 0.4849 - val_loss: 1.5109 - val_accuracy: 0.4307\n","Epoch 23/100\n","29/28 [==============================] - ETA: -5s - loss: 1.5285 - accuracy: 0.4526"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n","WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r28/28 [==============================] - 175s 6s/step - loss: 1.5285 - accuracy: 0.4526 - val_loss: 1.4074 - val_accuracy: 0.4717\n","Epoch 24/100\n","29/28 [==============================] - ETA: -4s - loss: 1.4035 - accuracy: 0.4731"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n","WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r28/28 [==============================] - 156s 6s/step - loss: 1.4035 - accuracy: 0.4731 - val_loss: 1.5084 - val_accuracy: 0.4785\n","Epoch 25/100\n","29/28 [==============================] - ETA: -4s - loss: 1.5780 - accuracy: 0.4752"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n","WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r28/28 [==============================] - 152s 5s/step - loss: 1.5780 - accuracy: 0.4752 - val_loss: 1.7475 - val_accuracy: 0.4219\n","Epoch 26/100\n","29/28 [==============================] - ETA: -4s - loss: 1.4825 - accuracy: 0.4709"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n","WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r28/28 [==============================] - 155s 6s/step - loss: 1.4825 - accuracy: 0.4709 - val_loss: 1.3163 - val_accuracy: 0.5244\n","Epoch 27/100\n","29/28 [==============================] - ETA: -4s - loss: 1.3868 - accuracy: 0.4903"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n","WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r28/28 [==============================] - 150s 5s/step - loss: 1.3868 - accuracy: 0.4903 - val_loss: 1.3208 - val_accuracy: 0.5205\n","Epoch 28/100\n","29/28 [==============================] - ETA: -4s - loss: 1.4279 - accuracy: 0.4838"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n","WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r28/28 [==============================] - 144s 5s/step - loss: 1.4279 - accuracy: 0.4838 - val_loss: 1.7313 - val_accuracy: 0.4414\n"]}]},{"cell_type":"code","source":["# fit the model\n","r = model.fit_generator(\n","  training_set,\n","  validation_data=test_set,\n","  epochs=2,\n","  steps_per_epoch=len(training_set)/32,\n","  validation_steps=len(test_set)/32\n",")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"tObKMZPrjgjZ","outputId":"9c3fb38e-dd65-4649-f5ee-3ea32cad4837","executionInfo":{"status":"ok","timestamp":1670064422910,"user_tz":-300,"elapsed":1125082,"user":{"displayName":"Zainab Bibi","userId":"04957673229875639387"}}},"execution_count":17,"outputs":[{"output_type":"stream","name":"stderr","text":["<ipython-input-17-772127a97c78>:2: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n","  r = model.fit_generator(\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 1/2\n","28/28 [==============================] - 559s 20s/step - loss: 2.2288 - accuracy: 0.2284 - val_loss: 1.8747 - val_accuracy: 0.3281\n","Epoch 2/2\n","28/28 [==============================] - 536s 19s/step - loss: 1.7491 - accuracy: 0.3168 - val_loss: 1.7855 - val_accuracy: 0.3164\n"]}]},{"cell_type":"code","source":["from datetime import datetime\n","from keras.callbacks import ModelCheckpoint, EarlyStopping\n","# checkpoint = ModelCheckpoint(filepath='mymodel.h5', verbose=1, save_best_only=True)\n","# callbacks = [checkpoint]\n","start = datetime.now()\n","\n","early = EarlyStopping(monitor='val_acc', min_delta=0, patience=20, verbose=1, mode='auto')\n","checkpoint = ModelCheckpoint(\"vgg16_1.h5\", monitor='val_acc', verbose=1, save_best_only=True, save_weights_only=False, mode='auto', period=1)\n","model_history=model.fit_generator(\n","  training_set,\n","  validation_data=test_set,\n","  epochs=20,\n","  steps_per_epoch=5,\n","  validation_steps=32,\n","  callbacks=[checkpoint,early],\n","  verbose=1)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2DF9DIr-rQSX","executionInfo":{"status":"ok","timestamp":1670069322865,"user_tz":-300,"elapsed":3739402,"user":{"displayName":"Zainab Bibi","userId":"04957673229875639387"}},"outputId":"7d3cd3e7-2208-4d43-eaaf-cac59aa5d8fa"},"execution_count":22,"outputs":[{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n","<ipython-input-22-e640200b4647>:9: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n","  model_history=model.fit_generator(\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 1/20\n","5/5 [==============================] - ETA: 0s - loss: 1.7025 - accuracy: 0.3000 "]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n","WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r5/5 [==============================] - 399s 96s/step - loss: 1.7025 - accuracy: 0.3000 - val_loss: 1.8806 - val_accuracy: 0.3447\n","Epoch 2/20\n","5/5 [==============================] - ETA: 0s - loss: 1.7606 - accuracy: 0.3938 "]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n","WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r5/5 [==============================] - 343s 83s/step - loss: 1.7606 - accuracy: 0.3938 - val_loss: 1.6634 - val_accuracy: 0.4004\n","Epoch 3/20\n","5/5 [==============================] - ETA: 0s - loss: 1.7776 - accuracy: 0.3875 "]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n","WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r5/5 [==============================] - 289s 69s/step - loss: 1.7776 - accuracy: 0.3875 - val_loss: 1.5825 - val_accuracy: 0.4141\n","Epoch 4/20\n","5/5 [==============================] - ETA: 0s - loss: 1.7982 - accuracy: 0.3938 "]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n","WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r5/5 [==============================] - 257s 61s/step - loss: 1.7982 - accuracy: 0.3938 - val_loss: 1.6716 - val_accuracy: 0.3662\n","Epoch 5/20\n","5/5 [==============================] - ETA: 0s - loss: 1.6395 - accuracy: 0.3625 "]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n","WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r5/5 [==============================] - 241s 57s/step - loss: 1.6395 - accuracy: 0.3625 - val_loss: 1.6569 - val_accuracy: 0.3789\n","Epoch 6/20\n","5/5 [==============================] - ETA: 0s - loss: 1.6314 - accuracy: 0.4125 "]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n","WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r5/5 [==============================] - 216s 51s/step - loss: 1.6314 - accuracy: 0.4125 - val_loss: 1.6346 - val_accuracy: 0.3721\n","Epoch 7/20\n","5/5 [==============================] - ETA: 0s - loss: 1.7309 - accuracy: 0.3375 "]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n","WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r5/5 [==============================] - 199s 46s/step - loss: 1.7309 - accuracy: 0.3375 - val_loss: 1.4952 - val_accuracy: 0.4238\n","Epoch 8/20\n","5/5 [==============================] - ETA: 0s - loss: 1.6289 - accuracy: 0.3500 "]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n","WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r5/5 [==============================] - 192s 44s/step - loss: 1.6289 - accuracy: 0.3500 - val_loss: 1.5983 - val_accuracy: 0.3828\n","Epoch 9/20\n","5/5 [==============================] - ETA: 0s - loss: 1.6456 - accuracy: 0.3250 "]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n","WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r5/5 [==============================] - 154s 35s/step - loss: 1.6456 - accuracy: 0.3250 - val_loss: 1.5420 - val_accuracy: 0.3857\n","Epoch 10/20\n","5/5 [==============================] - ETA: 0s - loss: 1.7561 - accuracy: 0.3500 "]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n","WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r5/5 [==============================] - 147s 33s/step - loss: 1.7561 - accuracy: 0.3500 - val_loss: 1.6890 - val_accuracy: 0.3662\n","Epoch 11/20\n","5/5 [==============================] - ETA: 0s - loss: 1.7142 - accuracy: 0.4437 "]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n","WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r5/5 [==============================] - 130s 29s/step - loss: 1.7142 - accuracy: 0.4437 - val_loss: 1.5616 - val_accuracy: 0.3887\n","Epoch 12/20\n","5/5 [==============================] - ETA: 0s - loss: 1.6547 - accuracy: 0.3375 "]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n","WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r5/5 [==============================] - 129s 29s/step - loss: 1.6547 - accuracy: 0.3375 - val_loss: 1.6249 - val_accuracy: 0.3848\n","Epoch 13/20\n","5/5 [==============================] - ETA: 0s - loss: 1.6779 - accuracy: 0.4125 "]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n","WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r5/5 [==============================] - 111s 25s/step - loss: 1.6779 - accuracy: 0.4125 - val_loss: 1.5703 - val_accuracy: 0.4180\n","Epoch 14/20\n","5/5 [==============================] - ETA: 0s - loss: 1.6967 - accuracy: 0.3375 "]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n","WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r5/5 [==============================] - 107s 24s/step - loss: 1.6967 - accuracy: 0.3375 - val_loss: 1.7274 - val_accuracy: 0.4082\n","Epoch 15/20\n","5/5 [==============================] - ETA: 0s - loss: 1.8890 - accuracy: 0.4062 "]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n","WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r5/5 [==============================] - 95s 21s/step - loss: 1.8890 - accuracy: 0.4062 - val_loss: 1.5508 - val_accuracy: 0.4111\n","Epoch 16/20\n","5/5 [==============================] - ETA: 0s - loss: 1.5535 - accuracy: 0.4250 "]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n","WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r5/5 [==============================] - 91s 20s/step - loss: 1.5535 - accuracy: 0.4250 - val_loss: 1.6744 - val_accuracy: 0.3750\n","Epoch 17/20\n","5/5 [==============================] - ETA: 0s - loss: 1.5277 - accuracy: 0.4062 "]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n","WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r5/5 [==============================] - 93s 20s/step - loss: 1.5277 - accuracy: 0.4062 - val_loss: 1.7583 - val_accuracy: 0.3711\n","Epoch 18/20\n","5/5 [==============================] - ETA: 0s - loss: 1.5844 - accuracy: 0.4313 "]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n","WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r5/5 [==============================] - 86s 18s/step - loss: 1.5844 - accuracy: 0.4313 - val_loss: 1.6747 - val_accuracy: 0.3799\n","Epoch 19/20\n","5/5 [==============================] - ETA: 0s - loss: 1.5165 - accuracy: 0.4187 "]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n","WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r5/5 [==============================] - 82s 17s/step - loss: 1.5165 - accuracy: 0.4187 - val_loss: 1.6947 - val_accuracy: 0.4072\n","Epoch 20/20\n","5/5 [==============================] - ETA: 0s - loss: 1.5711 - accuracy: 0.4437 "]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n","WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r5/5 [==============================] - 73s 15s/step - loss: 1.5711 - accuracy: 0.4437 - val_loss: 1.5383 - val_accuracy: 0.4307\n"]}]},{"cell_type":"code","source":["# fit the model\n","r = model.fit_generator(\n","  training_set,\n","  validation_data=test_set,\n","  epochs=50,\n","  steps_per_epoch=len(training_set)/32,\n","  validation_steps=len(test_set)/32\n",")"],"metadata":{"id":"SWpAr-HyMXjM","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1669955459527,"user_tz":-300,"elapsed":2992524,"user":{"displayName":"Zainab Bibi","userId":"04957673229875639387"}},"outputId":"fdac3e6a-2d53-4ed1-d737-a3a858684569"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["<ipython-input-22-4d9293e0cd75>:2: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n","  r = model.fit_generator(\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 1/50\n","28/28 [==============================] - 212s 8s/step - loss: 1.4191 - accuracy: 0.4677 - val_loss: 1.5525 - val_accuracy: 0.4688\n","Epoch 2/50\n","28/28 [==============================] - 102s 4s/step - loss: 1.4190 - accuracy: 0.4731 - val_loss: 1.4633 - val_accuracy: 0.4141\n","Epoch 3/50\n","28/28 [==============================] - 88s 3s/step - loss: 1.6274 - accuracy: 0.4375 - val_loss: 1.6024 - val_accuracy: 0.4258\n","Epoch 4/50\n","28/28 [==============================] - 82s 3s/step - loss: 1.4254 - accuracy: 0.4591 - val_loss: 1.4947 - val_accuracy: 0.4570\n","Epoch 5/50\n","28/28 [==============================] - 83s 3s/step - loss: 1.4815 - accuracy: 0.4800 - val_loss: 1.3338 - val_accuracy: 0.5078\n","Epoch 6/50\n","28/28 [==============================] - 77s 3s/step - loss: 1.3491 - accuracy: 0.5054 - val_loss: 1.4343 - val_accuracy: 0.4961\n","Epoch 7/50\n","28/28 [==============================] - 75s 3s/step - loss: 1.4654 - accuracy: 0.4849 - val_loss: 1.3019 - val_accuracy: 0.5117\n","Epoch 8/50\n","28/28 [==============================] - 72s 3s/step - loss: 1.3605 - accuracy: 0.4957 - val_loss: 1.4279 - val_accuracy: 0.4648\n","Epoch 9/50\n","28/28 [==============================] - 74s 3s/step - loss: 1.3848 - accuracy: 0.5269 - val_loss: 1.4558 - val_accuracy: 0.4961\n","Epoch 10/50\n","28/28 [==============================] - 75s 3s/step - loss: 1.4430 - accuracy: 0.4957 - val_loss: 1.5125 - val_accuracy: 0.4336\n","Epoch 11/50\n","28/28 [==============================] - 68s 2s/step - loss: 1.4205 - accuracy: 0.4903 - val_loss: 1.7504 - val_accuracy: 0.3984\n","Epoch 12/50\n","28/28 [==============================] - 62s 2s/step - loss: 1.5428 - accuracy: 0.4644 - val_loss: 1.4801 - val_accuracy: 0.4688\n","Epoch 13/50\n","28/28 [==============================] - 66s 2s/step - loss: 1.5096 - accuracy: 0.4666 - val_loss: 1.3641 - val_accuracy: 0.5117\n","Epoch 14/50\n","28/28 [==============================] - 65s 2s/step - loss: 1.3753 - accuracy: 0.5097 - val_loss: 1.4923 - val_accuracy: 0.4492\n","Epoch 15/50\n","28/28 [==============================] - 60s 2s/step - loss: 1.3121 - accuracy: 0.5302 - val_loss: 1.4124 - val_accuracy: 0.5000\n","Epoch 16/50\n","28/28 [==============================] - 60s 2s/step - loss: 1.3359 - accuracy: 0.5075 - val_loss: 1.3208 - val_accuracy: 0.5312\n","Epoch 17/50\n","28/28 [==============================] - 60s 2s/step - loss: 1.2806 - accuracy: 0.5345 - val_loss: 1.5574 - val_accuracy: 0.4609\n","Epoch 18/50\n","28/28 [==============================] - 57s 2s/step - loss: 1.3486 - accuracy: 0.5140 - val_loss: 1.4839 - val_accuracy: 0.4883\n","Epoch 19/50\n","28/28 [==============================] - 57s 2s/step - loss: 1.3978 - accuracy: 0.4892 - val_loss: 1.4495 - val_accuracy: 0.4805\n","Epoch 20/50\n","28/28 [==============================] - 56s 2s/step - loss: 1.4267 - accuracy: 0.5065 - val_loss: 1.3452 - val_accuracy: 0.4844\n","Epoch 21/50\n","28/28 [==============================] - 51s 2s/step - loss: 1.4410 - accuracy: 0.5054 - val_loss: 1.6606 - val_accuracy: 0.4258\n","Epoch 22/50\n","28/28 [==============================] - 50s 2s/step - loss: 1.4290 - accuracy: 0.4925 - val_loss: 1.3977 - val_accuracy: 0.4805\n","Epoch 23/50\n","28/28 [==============================] - 52s 2s/step - loss: 1.3764 - accuracy: 0.5065 - val_loss: 1.4870 - val_accuracy: 0.4883\n","Epoch 24/50\n","28/28 [==============================] - 51s 2s/step - loss: 1.3326 - accuracy: 0.5248 - val_loss: 1.5968 - val_accuracy: 0.4570\n","Epoch 25/50\n","28/28 [==============================] - 48s 2s/step - loss: 1.4409 - accuracy: 0.4741 - val_loss: 1.3285 - val_accuracy: 0.5117\n","Epoch 26/50\n","28/28 [==============================] - 45s 2s/step - loss: 1.3464 - accuracy: 0.5119 - val_loss: 1.3539 - val_accuracy: 0.5000\n","Epoch 27/50\n","28/28 [==============================] - 44s 2s/step - loss: 1.3608 - accuracy: 0.5172 - val_loss: 1.6335 - val_accuracy: 0.4844\n","Epoch 28/50\n","28/28 [==============================] - 48s 2s/step - loss: 1.3883 - accuracy: 0.5011 - val_loss: 1.4611 - val_accuracy: 0.4727\n","Epoch 29/50\n","28/28 [==============================] - 45s 2s/step - loss: 1.3669 - accuracy: 0.5162 - val_loss: 1.5188 - val_accuracy: 0.4570\n","Epoch 30/50\n","28/28 [==============================] - 42s 2s/step - loss: 1.4043 - accuracy: 0.4876 - val_loss: 1.4998 - val_accuracy: 0.4883\n","Epoch 31/50\n","28/28 [==============================] - 40s 1s/step - loss: 1.3192 - accuracy: 0.5011 - val_loss: 1.3030 - val_accuracy: 0.5469\n","Epoch 32/50\n","28/28 [==============================] - 38s 1s/step - loss: 1.3017 - accuracy: 0.5075 - val_loss: 1.2932 - val_accuracy: 0.5703\n","Epoch 33/50\n","28/28 [==============================] - 38s 1s/step - loss: 1.3362 - accuracy: 0.5162 - val_loss: 1.4829 - val_accuracy: 0.4688\n","Epoch 34/50\n","28/28 [==============================] - 42s 1s/step - loss: 1.3968 - accuracy: 0.5248 - val_loss: 1.5315 - val_accuracy: 0.4453\n","Epoch 35/50\n","28/28 [==============================] - 41s 1s/step - loss: 1.3291 - accuracy: 0.5259 - val_loss: 1.3611 - val_accuracy: 0.5117\n","Epoch 36/50\n","28/28 [==============================] - 36s 1s/step - loss: 1.3274 - accuracy: 0.5291 - val_loss: 1.7836 - val_accuracy: 0.4102\n","Epoch 37/50\n","28/28 [==============================] - 37s 1s/step - loss: 1.3467 - accuracy: 0.4978 - val_loss: 1.3465 - val_accuracy: 0.5234\n","Epoch 38/50\n","28/28 [==============================] - 38s 1s/step - loss: 1.3794 - accuracy: 0.4989 - val_loss: 1.7923 - val_accuracy: 0.3984\n","Epoch 39/50\n","28/28 [==============================] - 29s 964ms/step - loss: 1.4606 - accuracy: 0.5000 - val_loss: 1.5477 - val_accuracy: 0.4609\n","Epoch 40/50\n","28/28 [==============================] - 33s 1s/step - loss: 1.4876 - accuracy: 0.4828 - val_loss: 1.3924 - val_accuracy: 0.5195\n","Epoch 41/50\n","28/28 [==============================] - 29s 1s/step - loss: 1.3036 - accuracy: 0.5119 - val_loss: 1.2376 - val_accuracy: 0.5273\n","Epoch 42/50\n","28/28 [==============================] - 32s 1s/step - loss: 1.2982 - accuracy: 0.5431 - val_loss: 1.2147 - val_accuracy: 0.5469\n","Epoch 43/50\n","28/28 [==============================] - 33s 1s/step - loss: 1.4766 - accuracy: 0.4817 - val_loss: 1.8400 - val_accuracy: 0.4492\n","Epoch 44/50\n","28/28 [==============================] - 32s 1s/step - loss: 1.5151 - accuracy: 0.4957 - val_loss: 1.5256 - val_accuracy: 0.4922\n","Epoch 45/50\n","28/28 [==============================] - 34s 1s/step - loss: 1.2813 - accuracy: 0.5291 - val_loss: 1.5470 - val_accuracy: 0.4414\n","Epoch 46/50\n","28/28 [==============================] - 31s 1s/step - loss: 1.4439 - accuracy: 0.4860 - val_loss: 2.0821 - val_accuracy: 0.3945\n","Epoch 47/50\n","28/28 [==============================] - 30s 1s/step - loss: 1.3949 - accuracy: 0.5172 - val_loss: 1.5867 - val_accuracy: 0.4727\n","Epoch 48/50\n","28/28 [==============================] - 27s 960ms/step - loss: 1.4409 - accuracy: 0.5269 - val_loss: 1.3254 - val_accuracy: 0.5195\n","Epoch 49/50\n","28/28 [==============================] - 26s 898ms/step - loss: 1.3318 - accuracy: 0.5183 - val_loss: 1.3684 - val_accuracy: 0.5195\n","Epoch 50/50\n","28/28 [==============================] - 30s 1s/step - loss: 1.2634 - accuracy: 0.5302 - val_loss: 1.5190 - val_accuracy: 0.4883\n"]}]},{"cell_type":"code","source":["# loss\n","plt.plot(r.history['loss'], label='train loss')\n","plt.plot(r.history['val_loss'], label='val loss')\n","plt.legend()\n","plt.show()\n","plt.savefig('LossVal_loss')"],"metadata":{"id":"XiPTHtX-Motw"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# accuracies\n","plt.plot(r.history['acc'], label='train acc')\n","plt.plot(r.history['val_acc'], label='val acc')\n","plt.legend()\n","plt.show()\n","plt.savefig('AccVal_acc')"],"metadata":{"id":"0SCcSJBxMowf"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"blgQDtWuM13l"},"execution_count":null,"outputs":[]}]}